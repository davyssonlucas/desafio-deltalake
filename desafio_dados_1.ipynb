{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a3c00ae",
   "metadata": {},
   "source": [
    "# Desafio de Dados:\n",
    "<img src =  \"assets/photo_2023-10-25_21-25-10.jpg\">\n",
    "\n",
    "**Teremos 5 camadas em nossa estrutura, cada camada será representada por uma pasta dentro do bucket.**\n",
    "\n",
    "**Bucket D2D**\n",
    "\n",
    "<span style=\"font-weight: bold;\">\n",
    "\n",
    "- Transient -1\n",
    "- Raw -2\n",
    "- Trusted -3\n",
    "- Refined -4\n",
    "- Sandbox\n",
    "  - Transient\n",
    "  - Raw\n",
    "  - Trusted\n",
    "  - Refined\n",
    "  \n",
    "</span>\n",
    "  \n",
    "# CONSTRUINDO A SOLUÇÃO:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cadd1a5c-f4cc-4a53-88e2-646446fad170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importando as bibliotecas necessárias\n"
     ]
    }
   ],
   "source": [
    "# Importa as bibliotecas necessárias\n",
    "print(\"Importando as bibliotecas necessárias\")\n",
    "import os\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f93cae-08c5-40e0-9394-51e03016de79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurando a variável de ambiente PYSPARK_SUBMIT_ARGS\n",
      "Iniciando a sessão Spark\n",
      "Configurando as configurações do MinIO\n"
     ]
    }
   ],
   "source": [
    "# Configura a variável de ambiente PYSPARK_SUBMIT_ARGS\n",
    "print(\"Configurando a variável de ambiente PYSPARK_SUBMIT_ARGS\")\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.hadoop:hadoop-aws:3.3.1 pyspark-shell'\n",
    "\n",
    "# Cria uma sessão Spark\n",
    "print(\"Iniciando a sessão Spark\")\n",
    "spark = SparkSession.builder.appName(\"ExemploMinIO\").getOrCreate()\n",
    "\n",
    "# Configura as configurações do MinIO (caso não estejam definidas em PYSPARK_SUBMIT_ARGS)\n",
    "print(\"Configurando as configurações do MinIO\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", \"qiBoC6oxvaAdlFCR9I9p\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", \"vjHjYMCp6fbWyHjO3iFHewSggT0lWiCBFNGVKiu2\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"http://172.17.59.191:9000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd660ece-63fa-4e59-abc6-3269574d12c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definindo variáveis\n",
      "Criando um DataFrame\n",
      "Salvando o DataFrame diretamente no MinIO\n",
      "DataFrame no bucket do MinIO\n"
     ]
    }
   ],
   "source": [
    "print(\"Definindo variáveis\")\n",
    "minio_bucket_name = \"d2d\"\n",
    "minio_path = \"transient/arquivo_teste_1\"  # O caminho no MinIO onde será salvo\n",
    "\n",
    "# Cria um DataFrame\n",
    "print(\"Criando um DataFrame\")\n",
    "df = spark.createDataFrame([(1, \"Lucas\", 28), (2, \"Alana\", 22), \n",
    "                            (3, \"Gabrielly\", 45), (4, \"Isabela\", 4), \n",
    "                            (5, \"Jhonny\",1), (6, \"Fernando\", 60)], \n",
    "                           [\"id\", \"nome\", \"idade\"])\n",
    "\n",
    "# Salva o DataFrame diretamente no MinIO\n",
    "print(\"Salvando o DataFrame diretamente no MinIO\")\n",
    "df.write.format(\"parquet\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"path\", f\"s3a://{minio_bucket_name}/{minio_path}\") \\\n",
    "    .save()\n",
    "print(\"DataFrame no bucket do MinIO\")\n",
    "\n",
    "# Encerra a sessão Spark\n",
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c714bdbf-f0cd-402e-bfc1-9ac5409988b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+\n",
      "| id|     nome|idade|\n",
      "+---+---------+-----+\n",
      "|  3|Gabrielly|   45|\n",
      "|  6| Fernando|   60|\n",
      "|  4|  Isabela|    4|\n",
      "|  5|   Jhonny|    1|\n",
      "|  1|    Lucas|   28|\n",
      "|  2|    Alana|   22|\n",
      "+---+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ler o arquivo salvo\n",
    "arq = spark.read.parquet(f\"s3a://{minio_bucket_name}/{minio_path}\")\n",
    "arq.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f3e1ac-0611-46a8-973f-50c8c5d8e7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessão spark encerrada\n"
     ]
    }
   ],
   "source": [
    "# Encerra a sessão Spark\n",
    "print(\"Sessão spark encerrada\")\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
